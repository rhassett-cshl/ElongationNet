{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/grid/siepel/home_norepl/hassett/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3553: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  seqnames    start      end strand  ensembl_gene_id    score      ctcf  \\\n",
      "0        1  1002760  1002760      +  ENSG00000187608  0.00000 -0.124708   \n",
      "1        1  1002761  1002761      +  ENSG00000187608  0.00000 -0.124708   \n",
      "2        1  1002762  1002762      +  ENSG00000187608  0.00000 -0.124708   \n",
      "3        1  1002763  1002763      +  ENSG00000187608  0.00000 -0.124708   \n",
      "4        1  1002764  1002764      +  ENSG00000187608  0.62265 -0.124708   \n",
      "\n",
      "   h4k20me1  h3k79me2   h3k4me1  ...       sj5      sj3      rpts  wgbs  \\\n",
      "0  -0.47533 -0.202922 -0.276494  ... -0.012938  0.04604 -0.187111   0.0   \n",
      "1  -0.47533 -0.202922 -0.276494  ... -0.012938  0.04604 -0.187111   0.0   \n",
      "2  -0.47533 -0.202922 -0.276494  ... -0.012938  0.04604 -0.187111   0.0   \n",
      "3  -0.47533 -0.202922 -0.276494  ... -0.012938  0.04604 -0.187111   0.0   \n",
      "4  -0.47533 -0.202922 -0.276494  ... -0.012938  0.04604 -0.187111   0.0   \n",
      "\n",
      "   lambda_alphaj      zeta  A  T  G  C  \n",
      "0       0.044328  1.066961  0  0  1  0  \n",
      "1       0.044328  1.066961  0  0  0  1  \n",
      "2       0.044328  1.066961  0  0  0  1  \n",
      "3       0.044328  1.066961  0  1  0  0  \n",
      "4       0.044328  1.066961  0  0  0  1  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# File path for saving\n",
    "filename = './data/mcf7_datasets.pkl'\n",
    "\n",
    "froot = './data/mcf7_epAllmer_norm.csv'\n",
    "df = pd.read_csv(froot)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: 136927782\n",
      "val data size: 17166667\n",
      "test data size: 17113151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train size = 80%, validation size = 10%, test size = 10%\n",
    "train_size = 0.8\n",
    "\n",
    "grouped = df.groupby('ensembl_gene_id')\n",
    "\n",
    "# split by gene into train, val, test sets\n",
    "train_idx, temp_idx = train_test_split(list(grouped.groups.keys()), test_size=(1.0 - train_size), random_state=42)\n",
    "val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=42)\n",
    "\n",
    "# create dictionary mapping each gene id to its assigned train, val, test dataset labels\n",
    "dataset_mapping = {gene_id: 'train' for gene_id in train_idx}\n",
    "dataset_mapping.update({gene_id: 'val' for gene_id in val_idx})\n",
    "dataset_mapping.update({gene_id: 'test' for gene_id in test_idx})\n",
    "\n",
    "# filter rows based on assigned dataset field\n",
    "df['dataset'] = df['ensembl_gene_id'].map(dataset_mapping)\n",
    "train_data = df[df['dataset'] == 'train']\n",
    "valid_data = df[df['dataset'] == 'val']\n",
    "test_data = df[df['dataset'] == 'test']\n",
    "\n",
    "print(\"train data size: \" + str(len(train_data)))\n",
    "print(\"val data size: \" + str(len(valid_data)))\n",
    "print(\"test data size: \" + str(len(test_data)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seqnames                         1\n",
      "start                      1002760\n",
      "end                        1002760\n",
      "strand                           +\n",
      "ensembl_gene_id    ENSG00000187608\n",
      "score                          0.0\n",
      "ctcf                     -0.124708\n",
      "h4k20me1                  -0.47533\n",
      "h3k79me2                 -0.202922\n",
      "h3k4me1                  -0.276494\n",
      "h3k9me3                  -0.260088\n",
      "h3k36me3                 -0.680032\n",
      "sj5                      -0.012938\n",
      "sj3                        0.04604\n",
      "rpts                     -0.187111\n",
      "wgbs                           0.0\n",
      "lambda_alphaj             0.044328\n",
      "zeta                      1.066961\n",
      "A                                0\n",
      "T                                0\n",
      "G                                1\n",
      "C                                0\n",
      "dataset                      train\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_data.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train # genes: 2547\n",
      "val # genes: 318\n",
      "test # genes: 319\n"
     ]
    }
   ],
   "source": [
    "print(\"train # genes: \" + str(len(train_data.groupby('ensembl_gene_id'))))\n",
    "print(\"val # genes: \" + str(len(valid_data.groupby('ensembl_gene_id'))))\n",
    "print(\"test # genes: \" + str(len(test_data.groupby('ensembl_gene_id'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_datasets = {\n",
    "    'train': train_data,\n",
    "    'valid': valid_data,\n",
    "    'test': test_data\n",
    "}\n",
    "\n",
    "# Serialize the combined datasets to a pickle file with protocol=4 or higher\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(combined_datasets, file, protocol=pickle.HIGHEST_PROTOCOL) # protocol 4 for python >= 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seqnames                         1\n",
      "start                      1002760\n",
      "end                        1002760\n",
      "strand                           +\n",
      "ensembl_gene_id    ENSG00000187608\n",
      "score                          0.0\n",
      "ctcf                      -0.07771\n",
      "h4k20me1                 -0.429997\n",
      "h3k79me2                   -0.2804\n",
      "h3k4me1                  -0.217665\n",
      "h3k9me3                  -0.333359\n",
      "h3k36me3                 -0.801406\n",
      "sj5                      -0.039619\n",
      "sj3                      -0.059131\n",
      "rpts                     -0.187111\n",
      "wgbs                           0.0\n",
      "lambda_alphaj             0.026377\n",
      "zeta                      1.133344\n",
      "A                                0\n",
      "T                                0\n",
      "G                                1\n",
      "C                                0\n",
      "dataset                      train\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "with open(file_path, 'rb') as file:\n",
    "    combined_datasets = pickle.load(file)\n",
    "\n",
    "dataset1 = combined_datasets['train']\n",
    "\n",
    "print(dataset1.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda3 (Python 3.7.6)",
   "language": "python",
   "name": "anaconda3_2020.02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
