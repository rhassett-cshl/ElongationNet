{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1954549/4047503613.py:11: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  input_df = pd.read_csv(input_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  seqnames    start      end strand  ensembl_gene_id  score     ctcf  \\\n",
      "0        1  1002760  1002760      +  ENSG00000187608    0.0 -0.07771   \n",
      "1        1  1002761  1002761      +  ENSG00000187608    0.0 -0.07771   \n",
      "2        1  1002762  1002762      +  ENSG00000187608    0.0 -0.07771   \n",
      "3        1  1002763  1002763      +  ENSG00000187608    0.0 -0.07771   \n",
      "4        1  1002764  1002764      +  ENSG00000187608    0.0 -0.07771   \n",
      "\n",
      "   h4k20me1  h3k79me2   h3k4me1  ...       sj3      rpts  wgbs  lambda_alphaj  \\\n",
      "0 -0.429997   -0.2804 -0.217665  ... -0.059131 -0.187111   0.0       0.026377   \n",
      "1 -0.429997   -0.2804 -0.217665  ... -0.059131 -0.187111   0.0       0.026377   \n",
      "2 -0.429997   -0.2804 -0.217665  ... -0.059131 -0.187111   0.0       0.026377   \n",
      "3 -0.429997   -0.2804 -0.217665  ... -0.059131 -0.187111   0.0       0.026377   \n",
      "4 -0.429997   -0.2804 -0.217665  ... -0.059131 -0.187111   0.0       0.026377   \n",
      "\n",
      "       zeta  A  T  G  C  combined_zeta  \n",
      "0  1.133344  0  0  1  0       1.020207  \n",
      "1  1.133344  0  0  0  1       0.453937  \n",
      "2  1.133344  0  0  0  1       0.387068  \n",
      "3  1.133344  0  1  0  0       1.782512  \n",
      "4  1.133344  0  0  0  1       0.488461  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "   0\n",
      "0  1\n",
      "1  2\n",
      "2  3\n",
      "3  4\n",
      "4  5\n",
      "          0\n",
      "0  70396789\n",
      "1  70396790\n",
      "2  70396791\n",
      "3  70396792\n",
      "4  70396793\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "cell_type = \"k562\"\n",
    "\n",
    "# File path for saving\n",
    "pickle_file = f'./data/{cell_type}_analysis_datasets.pkl'\n",
    "\n",
    "input_file = f'./data/{cell_type}_epAllmer_zeta_norm.csv'\n",
    "input_df = pd.read_csv(input_file)\n",
    "\n",
    "# convert R csv file positions 1-based positions to 0-based for Python\n",
    "input_df['start'] = input_df['start'] - 1\n",
    "input_df['end'] = input_df['end'] - 1\n",
    "\n",
    "print(input_df.head())\n",
    "\n",
    "train_rows_file = \"./data/rowIndex_train_subset.csv\"\n",
    "test_rows_file = \"./data/rowIndex_test_subset.csv\"\n",
    "\n",
    "train_rows_df = pd.read_csv(train_rows_file, header=None)\n",
    "test_rows_df = pd.read_csv(test_rows_file, header=None)\n",
    "\n",
    "print(train_rows_df.head())\n",
    "print(test_rows_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                  0\n",
      "1                  1\n",
      "2                  2\n",
      "3                  3\n",
      "4                  4\n",
      "              ...   \n",
      "22450358    70359904\n",
      "22450359    70359905\n",
      "22450360    70359906\n",
      "22450361    70359907\n",
      "22450362    70359908\n",
      "Name: 0, Length: 22450363, dtype: int64\n",
      "0          70396788\n",
      "1          70396789\n",
      "2          70396790\n",
      "3          70396791\n",
      "4          70396792\n",
      "             ...   \n",
      "5596924    93335254\n",
      "5596925    93335255\n",
      "5596926    93335256\n",
      "5596927    93335257\n",
      "5596928    93335258\n",
      "Name: 0, Length: 5596929, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filter by row_index - 1 since row index file is 1-based and python data file is 0-based\n",
    "train_indices = train_rows_df[0] - 1\n",
    "test_indices = test_rows_df[0] - 1\n",
    "\n",
    "print(train_indices)\n",
    "print(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1954549/1942995380.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['dataset'] = 'train'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: 22450363\n",
      "valid data size: 0\n",
      "test data size: 5596929\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1954549/1942995380.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data['dataset'] = 'test'\n"
     ]
    }
   ],
   "source": [
    "train_data = input_df.iloc[train_indices]\n",
    "train_data['dataset'] = 'train'\n",
    "valid_data = pd.DataFrame(columns=input_df.columns)\n",
    "valid_data['dataset'] = 'valid'\n",
    "test_data = input_df.iloc[test_indices]\n",
    "test_data['dataset'] = 'test'\n",
    "\n",
    "print(\"train data size: \" + str(len(train_data)))\n",
    "print(\"valid data size: \" + str(len(valid_data)))\n",
    "print(\"test data size: \" + str(len(test_data)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seqnames                         1\n",
      "start                      1002760\n",
      "end                        1002760\n",
      "strand                           +\n",
      "ensembl_gene_id    ENSG00000187608\n",
      "score                          0.0\n",
      "ctcf                      -0.07771\n",
      "h4k20me1                 -0.429997\n",
      "h3k79me2                   -0.2804\n",
      "h3k4me1                  -0.217665\n",
      "h3k9me3                  -0.333359\n",
      "h3k36me3                 -0.801406\n",
      "sj5                      -0.039619\n",
      "sj3                      -0.059131\n",
      "rpts                     -0.187111\n",
      "wgbs                           0.0\n",
      "lambda_alphaj             0.026377\n",
      "zeta                      1.133344\n",
      "A                                0\n",
      "T                                0\n",
      "G                                1\n",
      "C                                0\n",
      "combined_zeta             1.020207\n",
      "dataset                      train\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_data.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train # genes: 402\n",
      "valid # genes: 0\n",
      "test # genes: 98\n"
     ]
    }
   ],
   "source": [
    "print(\"train # genes: \" + str(len(train_data.groupby('ensembl_gene_id'))))\n",
    "print(\"valid # genes: \" + str(len(valid_data.groupby('ensembl_gene_id'))))\n",
    "print(\"test # genes: \" + str(len(test_data.groupby('ensembl_gene_id'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_datasets = {\n",
    "    'train': train_data,\n",
    "    'valid': valid_data,\n",
    "    'test': test_data\n",
    "}\n",
    "\n",
    "# Serialize the combined datasets to a pickle file with protocol=4 or higher\n",
    "with open(pickle_file, 'wb') as file:\n",
    "    pickle.dump(combined_datasets, file, protocol=4) # protocol 4 for python >= 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seqnames                         1\n",
      "start                      1002760\n",
      "end                        1002760\n",
      "strand                           +\n",
      "ensembl_gene_id    ENSG00000187608\n",
      "score                          0.0\n",
      "ctcf                      -0.07771\n",
      "h4k20me1                 -0.429997\n",
      "h3k79me2                   -0.2804\n",
      "h3k4me1                  -0.217665\n",
      "h3k9me3                  -0.333359\n",
      "h3k36me3                 -0.801406\n",
      "sj5                      -0.039619\n",
      "sj3                      -0.059131\n",
      "rpts                     -0.187111\n",
      "wgbs                           0.0\n",
      "lambda_alphaj             0.026377\n",
      "zeta                      1.133344\n",
      "A                                0\n",
      "T                                0\n",
      "G                                1\n",
      "C                                0\n",
      "combined_zeta             1.020207\n",
      "dataset                      train\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "with open(pickle_file, 'rb') as file:\n",
    "    combined_datasets = pickle.load(file)\n",
    "\n",
    "dataset1 = combined_datasets['train']\n",
    "\n",
    "print(dataset1.iloc[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
